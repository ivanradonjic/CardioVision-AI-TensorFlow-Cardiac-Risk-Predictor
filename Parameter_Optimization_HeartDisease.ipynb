{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604f85c2-9cf5-455e-91c6-b5f0abea10cd",
   "metadata": {},
   "source": [
    "**Parameter Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf7a3e-34fd-4174-b16d-ea8de332485e",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36a67b8-8697-4f1e-82e9-f47e309a0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfcca0-6945-41c1-bc31-46d29d6c64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c7ca8-5a99-48b6-86f6-62a6fce3b076",
   "metadata": {},
   "source": [
    "FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13d9905-49de-425e-9769-f0582e7ee309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "def plot_accuracy(model_history):\n",
    "    plt.plot(model_history.history['accuracy'], label = 'Training Accuracy')\n",
    "    plt.plot(model_history.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "    plt.title(\"Accuracy of Model\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(model_history):\n",
    "    plt.plot(model_history.history['loss'], label = 'Training Loss')\n",
    "    plt.plot(model_history.history['val_loss'], label = 'Validation Loss')\n",
    "    plt.title(\"Loss of Model\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b934b67-dfff-4559-9465-c27f81470e94",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3d0b66-14c0-4000-b0b3-a53bb3a7932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  chest pain type  resting bp s  cholesterol  fasting blood sugar   \n",
       "0   40    1                2           140          289                    0  \\\n",
       "1   49    0                3           160          180                    0   \n",
       "2   37    1                2           130          283                    0   \n",
       "3   48    0                4           138          214                    0   \n",
       "4   54    1                3           150          195                    0   \n",
       "\n",
       "   resting ecg  max heart rate  exercise angina  oldpeak  ST slope  target  \n",
       "0            0             172                0      0.0         1       0  \n",
       "1            0             156                0      1.0         2       1  \n",
       "2            1              98                0      0.0         1       0  \n",
       "3            0             108                1      1.5         2       1  \n",
       "4            0             122                0      0.0         1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a5409f-1c6e-480f-b6c6-e0aaa1b2373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   age                  918 non-null    int64  \n",
      " 1   sex                  918 non-null    int64  \n",
      " 2   chest pain type      918 non-null    int64  \n",
      " 3   resting bp s         918 non-null    int64  \n",
      " 4   cholesterol          918 non-null    int64  \n",
      " 5   fasting blood sugar  918 non-null    int64  \n",
      " 6   resting ecg          918 non-null    int64  \n",
      " 7   max heart rate       918 non-null    int64  \n",
      " 8   exercise angina      918 non-null    int64  \n",
      " 9   oldpeak              918 non-null    float64\n",
      " 10  ST slope             918 non-null    int64  \n",
      " 11  target               918 non-null    int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 86.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7be65ba9-62c3-422e-a60a-68e88c0c0242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Lines of Input Data: [[ 40.    1.    2.  140.  289.    0.    0.  172.    0.    0.    1. ]\n",
      " [ 49.    0.    3.  160.  180.    0.    0.  156.    0.    1.    2. ]\n",
      " [ 37.    1.    2.  130.  283.    0.    1.   98.    0.    0.    1. ]\n",
      " [ 48.    0.    4.  138.  214.    0.    0.  108.    1.    1.5   2. ]\n",
      " [ 54.    1.    3.  150.  195.    0.    0.  122.    0.    0.    1. ]\n",
      " [ 39.    1.    3.  120.  339.    0.    0.  170.    0.    0.    1. ]]\n",
      "\n",
      "First 5 Lines of Target Data: [0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = df[df.columns[:-1]].values\n",
    "y = df[df.columns[-1]].values\n",
    "\n",
    "print(f\"First 5 Lines of Input Data: {X[0:6]}\")\n",
    "print(f\"\\nFirst 5 Lines of Target Data: {y[0:6]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4240e43-9db4-4028-b945-e8449698de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data set into training and test data\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.4, random_state = 0)\n",
    "#X_train and Y_train are now 60% of X/Y_transformed\n",
    "\n",
    "#X_temp and Y_temp are now 40% of X/Y_transformed\n",
    "#next line splits this last 40% in two parts, one for validation (20% of X/Y_transformed) and one for testing (20% of X/Y_transformed)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369f03d0-77f8-4385-955c-a7294243554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9214de3-86dd-4e01-8ef8-e6fae3b3b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial regularization Values\n",
    "regularization_values = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "#regularization values refined\n",
    "m1_reg_refined = [0.001,0.0019,0.0028,0.0037,0.0046,0.0055,0.0064,0.0073,0.0082,0.0091]\n",
    "m2_reg_refined = [0.00018, 0.00026, 0.00034, 0.00042, 0.0005, 0.00059, 0.00067, 0.00075, 0.00083, 0.00091]\n",
    "m3_reg_refined = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "m4_reg_refined = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "#Final Refined Regularization Values\n",
    "m1_reg = [0.001, 0.0064]\n",
    "m2_reg = [0.00026, 0.00067]\n",
    "m3_reg = [0.00072, 0.00083]\n",
    "m4_reg = [0.012, 0.013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b00195f8-16fc-4990-932d-3026b8c397bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refined Regularization Values with Learning Rate\n",
    "m1_reg_lr = [0.001]\n",
    "m2_reg_lr = [0.00018, 0.00026, 0.00067]\n",
    "m3_reg_lr = [0.00072, 0.00083, 0.0014, 0.0015]\n",
    "m4_reg_lr = [0.012, 0.013]\n",
    "\n",
    "#learning rate values \n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0b945d7-8502-46b8-b5aa-962ed7bcf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate Refined\n",
    "'''\n",
    "MODEL 1 INFO:\n",
    "Model 1 Regularization Parameter: 0.001\n",
    "Model 1 learning rate refined: 0.01 +-, m1_lr_refined\n",
    "'''\n",
    "m1_lr_refined = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "'''\n",
    "MODEL 2 INFO: \n",
    "Model 2 Regularization Parameters Refined: 1 - 0.00018, 2 - 0.00026, 3 - 0.00067\n",
    "Model 2 Regulaization Parameter 1 Learning Rate refined: 0.001 +-, m2_lr_refined_1\n",
    "Model 2 Regularization Paramter 2 learning Rate Refined: 0.01 +-, m2_lr_refined_2\n",
    "Model 2 Regulaization Parameter 3 Learning Rate Refined: 0.01 +-, m2_lr_refined_2\n",
    "'''\n",
    "m2_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "m2_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "'''\n",
    "MODEL 3 INFO:\n",
    "Model 3 Regularization Parameters Refined: 1 - 0.00072, 2 - 0.00083, 3 - 0.0014, 4 - 0.0015\n",
    "Model 3 Regulaization Parameter 1 Learning Rate refined: 0.001 +-, m5_lr_refined_1\n",
    "Model 3 Regulaization Parameter 2 Learning Rate refined: 0.01 +-, m5_lr_refined_2\n",
    "Model 3 Regulaization Parameter 3 Learning Rate refined: 0.01 +-, m5_lr_refined_2\n",
    "Model 3 Regulaization Parameter 4 Learning Rate refined: 0.01 +-, m5_lr_refined_2\n",
    "'''\n",
    "m3_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "m3_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "'''\n",
    "MODEL 4 INFO:\n",
    "Model 4 Regularization Parameters Refined: 1 - 0.012, 2 - 0.013\n",
    "Model 4 Regulaization Parameter 1 Learning Rate refined: 0.01 to 0.001, m7_lr_refined_1\n",
    "Model 4 Regulaization Parameter 2 Learning Rate refined: 0.001 to 0.0001, m7_lr_refined_2\n",
    "'''\n",
    "m4_lr_refined_1 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010]\n",
    "m4_lr_refined_2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434b00e-477b-4bd5-988c-77202681d18d",
   "metadata": {},
   "source": [
    "**MODEL 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f323828a-05ae-492c-a038-7f27235c5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the this and the following four code blocks to do an initial test on Model 1's structure\n",
    "'''\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='L1'),\n",
    "    tf.keras.layers.Dense(16, activation='relu', name='L2'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "model_1_history = model_1.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02345ff4-1e68-4b43-99d8-0414c98846d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(model_1_history)\n",
    "plot_loss(model_1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73619fe-ae4d-4c6d-a463-2d2a08610187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40500df5-9d0e-4987-9980-8ab540a1b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_m1 = model_1.predict(X_test)\n",
    "y_predicted_m1 = y_predicted_m1.flatten()\n",
    "y_predicted_m1 = np.where(y_predicted_m1 > 0.5, 1, 0)\n",
    "\n",
    "print(type(y_test))\n",
    "print(type(y_predicted_m1))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted_m1)\n",
    "print(cm)\n",
    "\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1c3be2-cac0-4198-adc7-dea80e91bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 1 with the generalized set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in regularization_values:\n",
    "#     print(f\"REGULARIZATION PARAMETER: {i}\")\n",
    "    \n",
    "#     model_1_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(16, activation='relu', name='L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(16, activation='relu', name='L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#     ])\n",
    "\n",
    "#     model_1_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_1_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_1_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     y_predicted_m1_reg = model_1_reg.predict(X_test)\n",
    "#     y_predicted_m1_reg = y_predicted_m1_reg.flatten()\n",
    "#     y_predicted_m1_reg = np.where(y_predicted_m1_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m1_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m1_reg))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f39c4-89fa-4bc5-9c37-71ae09eda758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 1 with its refined set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in m1_reg_refined:\n",
    "#     print(f\"REGULARIZATION PARAMETER: {i}\")\n",
    "    \n",
    "#     model_1_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(16, activation='relu', name='L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(16, activation='relu', name='L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#     ])\n",
    "\n",
    "#     model_1_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_1_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_1_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     y_predicted_m1_reg = model_1_reg.predict(X_test)\n",
    "#     y_predicted_m1_reg = y_predicted_m1_reg.flatten()\n",
    "#     y_predicted_m1_reg = np.where(y_predicted_m1_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m1_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m1_reg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96c928c-b69c-4a64-bf5d-55580027eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 1 with its refined regularization values,\n",
    "and its generalized set of learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m1_reg:\n",
    "#     for lr in learning_rates:\n",
    "#             print(f\"REGULARIZATION PARAMETER: {reg}\")\n",
    "#             print(f\"LEARNING RATE = {lr}\")\n",
    "            \n",
    "#             model_1_reg_lr = tf.keras.Sequential([\n",
    "#                 tf.keras.layers.Dense(16, activation='relu', name='L1', kernel_regularizer = l2(reg)),\n",
    "#                 tf.keras.layers.Dense(16, activation='relu', name='L2', kernel_regularizer = l2(reg)),\n",
    "#                 tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#             ])\n",
    "        \n",
    "#             model_1_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                     loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                     metrics = ['accuracy'])\n",
    "        \n",
    "#             history = model_1_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "        \n",
    "#             plot_accuracy(history)\n",
    "#             plot_loss(history)\n",
    "        \n",
    "#             print(\"\\nModel Prediction on Test set\")\n",
    "#             results= model_1_reg_lr.evaluate(X_test, y_test)\n",
    "        \n",
    "#             y_predicted_m1 = model_1_reg_lr.predict(X_test)\n",
    "#             y_predicted_m1 = y_predicted_m1.flatten()\n",
    "#             y_predicted_m1 = np.where(y_predicted_m1 > 0.5, 1, 0)\n",
    "        \n",
    "#             print(f\"\\nConfusion Matrix\")\n",
    "#             cm = confusion_matrix(y_test, y_predicted_m1)\n",
    "#             print(cm)\n",
    "        \n",
    "#             print(classification_report(y_test, y_predicted_m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e914048-f64a-4225-be80-fcaec9d99583",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and eevaluate Model 1 with its final regularization values, \n",
    "and refined learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m1_reg_lr:\n",
    "#     for lr in m1_lr_refined:\n",
    "#         print(f\"REGULARIZATION PARAMETER: {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "            \n",
    "#         model_1_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(16, activation='relu', name='L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(16, activation='relu', name='L2', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#         ])\n",
    "        \n",
    "#         model_1_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "        \n",
    "#         history = model_1_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "        \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "        \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_1_reg_lr.evaluate(X_test, y_test)\n",
    "        \n",
    "#         y_predicted_m1 = model_1_reg_lr.predict(X_test)\n",
    "#         y_predicted_m1 = y_predicted_m1.flatten()\n",
    "#         y_predicted_m1 = np.where(y_predicted_m1 > 0.5, 1, 0)\n",
    "        \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m1)\n",
    "#         print(cm)\n",
    "        \n",
    "#         print(classification_report(y_test, y_predicted_m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0306e27-d812-473f-8283-45d507aa7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test Final Configuration of Model 1\n",
    "'''\n",
    "\n",
    "# m1_reg_final = 0.001\n",
    "# m1_learning_rate_final = 0.011\n",
    "\n",
    "# print(f\"REGULARIZATION PARAMETER: {m1_reg_final}\")\n",
    "# print(f\"LEARNING RATE = {m1_learning_rate_final}\")\n",
    "                    \n",
    "# model_1 = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(16, activation='relu', name='L1', kernel_regularizer = l2(m1_reg_final)),\n",
    "#     tf.keras.layers.Dense(16, activation='relu', name='L2', kernel_regularizer = l2(m1_reg_final)),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "# ])\n",
    "                \n",
    "# model_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = m1_learning_rate_final),\n",
    "#                        loss = tf.keras.losses.BinaryCrossentropy(),  \n",
    "#                        metrics = ['accuracy'])\n",
    "                \n",
    "# history = model_1.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "                \n",
    "# plot_accuracy(history)\n",
    "# plot_loss(history)\n",
    "                \n",
    "# print(\"\\nModel Prediction on Test set\")\n",
    "# results= model_1.evaluate(X_test, y_test)\n",
    "                \n",
    "# y_predicted_m1 = model_1.predict(X_test)\n",
    "# y_predicted_m1 = y_predicted_m1.flatten()\n",
    "# y_predicted_m1 = np.where(y_predicted_m1 > 0.5, 1, 0)\n",
    "            \n",
    "# print(f\"\\nConfusion Matrix\")\n",
    "# cm = confusion_matrix(y_test, y_predicted_m1)\n",
    "# print(cm)\n",
    "\n",
    "# print(classification_report(y_test, y_predicted_m1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb363df0-6443-44f6-8c32-d6e543657b33",
   "metadata": {},
   "source": [
    "**MODEL 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7071a827-949b-4160-87a3-950cf6bab1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the this and the following four code blocks to do an initial test on Model 2's structure\n",
    "'''\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(25, activation = 'relu', name = 'L1'),\n",
    "    tf.keras.layers.Dense(15, activation = 'relu', name = 'L2'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "model_2_history = model_2.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420b7c2-6a4d-4c81-95f9-3599eed82ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(model_2_history)\n",
    "plot_loss(model_2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4910cb46-250b-4752-b857-d6357ab04743",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_m2 = model_2.predict(X_test)\n",
    "y_predicted_m2 = y_predicted_m2.flatten()\n",
    "y_predicted_m2 = np.where(y_predicted_m2 > 0.5, 1, 0)\n",
    "\n",
    "print(type(y_test))\n",
    "print(type(y_predicted_m2))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted_m2)\n",
    "print(cm)\n",
    "\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c9d88-79a1-4e04-8ffa-3f2007ffb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 2 with the generalized set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in regularization_values:\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "    \n",
    "#     model_2_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(25, activation = 'relu', name = 'L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(15, activation = 'relu', name = 'L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#     ])\n",
    "\n",
    "#     model_2_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_2_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_2_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m2_reg = model_2_reg.predict(X_test)\n",
    "#     y_predicted_m2_reg = y_predicted_m2_reg.flatten()\n",
    "#     y_predicted_m2_reg = np.where(y_predicted_m2_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m2_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m2_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29798a37-b152-4c2b-8628-3adf2ac3f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 2 with its refined set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in m2_reg_refined:\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "    \n",
    "#     model_2_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(25, activation = 'relu', name = 'L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(15, activation = 'relu', name = 'L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#     ])\n",
    "\n",
    "#     model_2_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_2_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_2_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m2_reg = model_2_reg.predict(X_test)\n",
    "#     y_predicted_m2_reg = y_predicted_m2_reg.flatten()\n",
    "#     y_predicted_m2_reg = np.where(y_predicted_m2_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m2_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m2_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be513095-4cd2-4575-84bf-5b2e4946bd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse the following for loop to train and evaluate Model 1 with its refined regularization values,\\nand its generalized set of learning rates.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 2 with its refined regularization values,\n",
    "and its generalized set of learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m2_reg:\n",
    "#     for lr in learning_rates:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "        \n",
    "#         model_2_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(25, activation = 'relu', name = 'L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(15, activation = 'relu', name = 'L2', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#         ])\n",
    "    \n",
    "#         model_2_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "    \n",
    "#         history = model_2_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "    \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_2_reg_lr.evaluate(X_test, y_test)\n",
    "    \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "    \n",
    "#         y_predicted_m2 = model_2_reg_lr.predict(X_test)\n",
    "#         y_predicted_m2 = y_predicted_m2.flatten()\n",
    "#         y_predicted_m2 = np.where(y_predicted_m2 > 0.5, 1, 0)\n",
    "    \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m2)\n",
    "#         print(cm)\n",
    "    \n",
    "#         print(classification_report(y_test, y_predicted_m2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e72f840-3f9f-402d-81e7-d403d9d20053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse the following for loop to train and eevaluate Model 2 with its final regularization values, \\nand refined learning rates.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Refined Regularization Parameters: m2_reg_lr = [0.00018, 0.00026, 0.00067]\n",
    "\n",
    "These are the refined Learning rates for each Regularization parameter\n",
    "\n",
    "0.00018 -> m2_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "0.00026, 0.00067 -> m2_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "Use the following for loop to train and eevaluate Model 2 with its final regularization values, \n",
    "and refined learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m2_reg_lr:           \n",
    "    \n",
    "#     learning_rate_for_reg_param = []\n",
    "    \n",
    "#     if reg == m2_reg_lr[0]:\n",
    "#         learning_rate_for_reg_param = m2_lr_refined_1\n",
    "#     else:\n",
    "#         learning_rate_for_reg_param = m2_lr_refined_2\n",
    "        \n",
    "#     for lr in learning_rate_for_reg_param:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "            \n",
    "#         model_2_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(25, activation = 'relu', name = 'L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(15, activation = 'relu', name = 'L2', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#             ])\n",
    "        \n",
    "#         model_2_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "        \n",
    "#         history = model_2_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "        \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_2_reg_lr.evaluate(X_test, y_test)\n",
    "        \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "        \n",
    "#         y_predicted_m2 = model_2_reg_lr.predict(X_test)\n",
    "#         y_predicted_m2 = y_predicted_m2.flatten()\n",
    "#         y_predicted_m2 = np.where(y_predicted_m2 > 0.5, 1, 0)\n",
    "        \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m2)\n",
    "#         print(cm)\n",
    "        \n",
    "#         print(classification_report(y_test, y_predicted_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d8f46-6625-4654-9899-88c8d4b27a9e",
   "metadata": {},
   "source": [
    "**MODEL 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d659e6a-501a-4c90-8d2f-72f7fefdf894",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the this and the following four code blocks to do an initial test on Model 3's structure\n",
    "'''\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation = 'relu', name = 'L1'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu', name = 'L2'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "model_3_history = model_3.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce811a-0b4c-4bd4-b7d2-9e39fe2b13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(model_3_history)\n",
    "plot_loss(model_3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df38c6-1fe6-4ee3-8ecd-e2816b140769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8380180-1937-4238-9a96-a930ae7a1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_m3 = model_3.predict(X_test)\n",
    "y_predicted_m3 = y_predicted_m3.flatten()\n",
    "y_predicted_m3 = np.where(y_predicted_m3 > 0.5, 1, 0)\n",
    "\n",
    "print(type(y_test))\n",
    "print(type(y_predicted_m3))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted_m3)\n",
    "print(cm)\n",
    "\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b519471-8f88-43a5-bdda-a16a814dc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 3 with the generalized set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in regularization_values:\n",
    "\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "\n",
    "#     model_3_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(64, activation = 'relu', name = 'L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(32, activation = 'relu', name = 'L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#     ])\n",
    "\n",
    "#     model_3_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_3_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_5_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m3_reg = model_3_reg.predict(X_test)\n",
    "#     y_predicted_m3_reg = y_predicted_m3_reg.flatten()\n",
    "#     y_predicted_m3_reg = np.where(y_predicted_m3_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m3_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m3_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d82cfa72-2537-4be3-abad-1376216f3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 3 with its refined set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in m3_reg_refined:\n",
    "\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "\n",
    "#     model_3_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(64, activation = 'relu', name = 'L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(32, activation = 'relu', name = 'L2', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#     ])\n",
    "\n",
    "#     model_3_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_3_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_3_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m3_reg = model_3_reg.predict(X_test)\n",
    "#     y_predicted_m3_reg = y_predicted_m3_reg.flatten()\n",
    "#     y_predicted_m3_reg = np.where(y_predicted_m3_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m3_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m3_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae75eb3-0d50-4c76-b75f-b19ac331f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse the following for loop to train and evaluate Model 3 with its refined regularization values,\\nand its generalized set of learning rates.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 3 with its refined regularization values,\n",
    "and its generalized set of learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m5_reg:\n",
    "#     for lr in learning_rates:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "    \n",
    "#         model_5_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(64, activation = 'relu', name = 'L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(32, activation = 'relu', name = 'L2', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#         ])\n",
    "    \n",
    "#         model_5_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "    \n",
    "#         history = model_5_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "    \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_5_reg_lr.evaluate(X_test, y_test)\n",
    "    \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "    \n",
    "#         y_predicted_m5 = model_5_reg_lr.predict(X_test)\n",
    "#         y_predicted_m5 = y_predicted_m5.flatten()\n",
    "#         y_predicted_m5 = np.where(y_predicted_m5 > 0.5, 1, 0)\n",
    "    \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m5)\n",
    "#         print(cm)\n",
    "    \n",
    "#         print(classification_report(y_test, y_predicted_m5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a25bc1-12e8-48e2-965e-23bcb305a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRefined Regularization Parameters: m5_reg_lr = [0.00072, 0.00083, 0.0014, 0.0015]\\n\\nThese are the refined Learning rates for each Regularization parameter\\nm5_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\\nm5_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\\n\\n0.00072 -> m5_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\\n0.00083, 0.0014, 0.0015 -> m5_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\\n\\nUse the following for loop to train and eevaluate Model 2 with its final regularization values, \\nand refined learning rates.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Refined Regularization Parameters: m3_reg_lr = [0.00072, 0.00083, 0.0014, 0.0015]\n",
    "\n",
    "These are the refined Learning rates for each Regularization parameter\n",
    "m3_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "m3_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "0.00072 -> m3_lr_refined_1 = [0.0005, 0.00061, 0.00072, 0.00083, 0.00094, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015]\n",
    "0.00083, 0.0014, 0.0015 -> m3_lr_refined_2 = [0.0054, 0.0063, 0.0072, 0.0081, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015]\n",
    "\n",
    "Use the following for loop to train and eevaluate Model 3 with its final regularization values, \n",
    "and refined learning rates.\n",
    "'''\n",
    "\n",
    "# for reg in m3_reg_lr:\n",
    "\n",
    "#     learning_rate_for_reg_param = []\n",
    "\n",
    "#     if reg == m3_reg_lr[0]:\n",
    "#         learning_rate_for_reg_param = m3_lr_refined_1\n",
    "#     else: \n",
    "#         learning_rate_for_reg_param = m3_lr_refined_2\n",
    "        \n",
    "#     for lr in learning_rate_for_reg_param:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "    \n",
    "#         model_3_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(64, activation = 'relu', name = 'L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(32, activation = 'relu', name = 'L2', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'OL')\n",
    "#         ])\n",
    "    \n",
    "#         model_3_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "    \n",
    "#         history = model_3_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "    \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_3_reg_lr.evaluate(X_test, y_test)\n",
    "    \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "    \n",
    "#         y_predicted_m3 = model_3_reg_lr.predict(X_test)\n",
    "#         y_predicted_m3 = y_predicted_m3.flatten()\n",
    "#         y_predicted_m3 = np.where(y_predicted_m3 > 0.5, 1, 0)\n",
    "    \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m3)\n",
    "#         print(cm)\n",
    "    \n",
    "#         print(classification_report(y_test, y_predicted_m3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f54972-10f1-4f88-8254-84b9fc1937c3",
   "metadata": {},
   "source": [
    "**MODEL 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4129cd0-8c5a-42fa-8bf0-ba490bb5aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the this and the following four code blocks to do an initial test on Model 4's structure\n",
    "'''\n",
    "\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', name='L1'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "model_4_history = model_4.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a75a07-ae20-459a-956c-b4a22a72c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(model_4_history)\n",
    "plot_loss(model_4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ac5be-a218-401c-b0fe-d23e90d64883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e02fe2-baf7-4c00-a56a-e46faf802d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_m4 = model_4.predict(X_test)\n",
    "y_predicted_m4 = y_predicted_m4.flatten()\n",
    "y_predicted_m4 = np.where(y_predicted_m4 > 0.5, 1, 0)\n",
    "\n",
    "print(type(y_test))\n",
    "print(type(y_predicted_m4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted_m4)\n",
    "print(cm)\n",
    "\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389fcda-7944-4312-bef6-1999539b2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 3 with the generalized set of regularization parameters\n",
    "'''\n",
    "# for i in regularization _values:\n",
    "\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "\n",
    "#     model_4_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(256, activation='relu', name='L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#     ])\n",
    "\n",
    "\n",
    "#     model_4_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_4_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_4_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m4_reg = model_4_reg.predict(X_test)\n",
    "#     y_predicted_m4_reg = y_predicted_m4_reg.flatten()\n",
    "#     y_predicted_m4_reg = np.where(y_predicted_m4_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m4_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m4_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e4ef4d2-3f6e-4d24-90d7-f4ebc48ece5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 4 with its refined set of regularization parameters\n",
    "'''\n",
    "\n",
    "# for i in m4_reg_refined:\n",
    "\n",
    "#     print(f\"REGULARIZATION PARAMETER {i}\")\n",
    "\n",
    "#     model_4_reg = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(256, activation='relu', name='L1', kernel_regularizer = l2(i)),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#     ])\n",
    "\n",
    "\n",
    "#     model_4_reg.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#             loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#             metrics = ['accuracy'])\n",
    "\n",
    "#     history = model_4_reg.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "#     print(\"\\nModel Prediction on Test set\")\n",
    "#     results= model_4_reg.evaluate(X_test, y_test)\n",
    "\n",
    "#     plot_accuracy(history)\n",
    "#     plot_loss(history)\n",
    "\n",
    "#     y_predicted_m4_reg = model_4_reg.predict(X_test)\n",
    "#     y_predicted_m4_reg = y_predicted_m4_reg.flatten()\n",
    "#     y_predicted_m4_reg = np.where(y_predicted_m4_reg > 0.5, 1, 0)\n",
    "\n",
    "#     print(f\"\\nConfusion Matrix\")\n",
    "#     cm = confusion_matrix(y_test, y_predicted_m4_reg)\n",
    "#     print(cm)\n",
    "\n",
    "#     print(classification_report(y_test, y_predicted_m4_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255f78fd-4244-4ba7-ac19-be37e0440d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse the following for loop to train and evaluate Model 3 with its refined regularization values,\\nand its generalized set of learning rates.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use the following for loop to train and evaluate Model 3 with its refined regularization values,\n",
    "and its generalized set of learning rates.\n",
    "'''\n",
    "# for reg in m7_reg:\n",
    "#     for lr in learning_rates:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "    \n",
    "#         model_7_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(256, activation='relu', name='L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#         ])\n",
    "    \n",
    "    \n",
    "#         model_7_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "    \n",
    "#         history = model_7_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "    \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_7_reg_lr.evaluate(X_test, y_test)\n",
    "    \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "    \n",
    "#         y_predicted_m7 = model_7_reg_lr.predict(X_test)\n",
    "#         y_predicted_m7 = y_predicted_m7.flatten()\n",
    "#         y_predicted_m7 = np.where(y_predicted_m7 > 0.5, 1, 0)\n",
    "    \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m7)\n",
    "#         print(cm)\n",
    "    \n",
    "#         print(classification_report(y_test, y_predicted_m7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44cc26bf-d856-4759-8de4-2f5dc77a0626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRefined Regularization Parameters: m4_reg_lr = [0.012, 0.013]\\n\\nThese are the refined Learning rates for each Regularization parameter\\nm4_lr_refined_1 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010]\\nm4_lr_refined_2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010]\\n\\n0.012 -> m4_lr_refined_1 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010]\\n0.013 -> m4_lr_refined_2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010]\\n\\nUse the following for loop to train and eevaluate Model 3 with its final regularization values, \\nand refined learning rates.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Refined Regularization Parameters: m4_reg_lr = [0.012, 0.013]\n",
    "\n",
    "These are the refined Learning rates for each Regularization parameter\n",
    "m4_lr_refined_1 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010]\n",
    "m4_lr_refined_2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010]\n",
    "\n",
    "0.012 -> m4_lr_refined_1 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010]\n",
    "0.013 -> m4_lr_refined_2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010]\n",
    "\n",
    "Use the following for loop to train and eevaluate Model 3 with its final regularization values, \n",
    "and refined learning rates.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for reg in m7_reg_lr:\n",
    "\n",
    "#     learning_rate_for_reg_param = []\n",
    "\n",
    "#     if reg == m7_reg_lr[0]:\n",
    "#         learning_rate_for_reg_param = m7_lr_refined_1\n",
    "#     else:\n",
    "#         learning_rate_for_reg_param = m7_lr_refined_2\n",
    "        \n",
    "#     for lr in learning_rate_for_reg_param:\n",
    "#         print(f\"REGULARIZATION PARAMETER {reg}\")\n",
    "#         print(f\"LEARNING RATE = {lr}\")\n",
    "    \n",
    "#         model_7_reg_lr = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(256, activation='relu', name='L1', kernel_regularizer = l2(reg)),\n",
    "#             tf.keras.layers.Dense(1, activation='sigmoid', name='OL')\n",
    "#         ])\n",
    "    \n",
    "#         model_7_reg_lr.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "#                 metrics = ['accuracy'])\n",
    "    \n",
    "#         history = model_7_reg_lr.fit(X_train, y_train, batch_size = 16, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "    \n",
    "#         print(\"\\nModel Prediction on Test set\")\n",
    "#         results= model_7_reg_lr.evaluate(X_test, y_test)\n",
    "    \n",
    "#         plot_accuracy(history)\n",
    "#         plot_loss(history)\n",
    "    \n",
    "#         y_predicted_m7 = model_7_reg_lr.predict(X_test)\n",
    "#         y_predicted_m7 = y_predicted_m7.flatten()\n",
    "#         y_predicted_m7 = np.where(y_predicted_m7 > 0.5, 1, 0)\n",
    "    \n",
    "#         print(f\"\\nConfusion Matrix\")\n",
    "#         cm = confusion_matrix(y_test, y_predicted_m7)\n",
    "#         print(cm)\n",
    "    \n",
    "#         print(classification_report(y_test, y_predicted_m7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f5ba5-0939-438e-986d-f05864e1b6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f3355-ec19-4f09-b8e5-8ceae91d003c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
